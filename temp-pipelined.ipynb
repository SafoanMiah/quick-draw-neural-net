{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm   \n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "from utils.model_train import train\n",
    "from utils.processing import load_data, process_data, augment_data, to_tensors, split_batch, incremental_save, partition_datasets\n",
    "from utils.quickdraw_cnn import QuickDrawCNN_V1, QuickDrawCNN_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"data/numpy_bitmap/\"\n",
    "datasets_dir = \"data/datasets\"\n",
    "categories = os.listdir(image_dir)\n",
    "categories = categories[:100]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "labels_map = {label: i for i, label in enumerate(set(categories))}\n",
    "reversed_labels_map = {v: k for k, v in labels_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image_dir: str, categories: list, device: torch.device, labels_map: dict):\n",
    "    \n",
    "    '''\n",
    "    A pipeline function to run the entire process of loading, processing, augmenting, and splitting the data onto each category at a time.\n",
    "    '''\n",
    "    \n",
    "    train_datasets, test_datasets, val_datasets = [], [], []\n",
    "\n",
    "    for cat in tqdm(categories, desc=\"Processing categories\"):\n",
    "        \n",
    "        try:\n",
    "            # load, process, augment, and split the data\n",
    "            features, label = load_data(image_dir, cat, file_standardize=False)\n",
    "            features, label = process_data(features, label)\n",
    "            mask = np.random.rand(len(features)) <= 0.003 # keep 30% of the data\n",
    "            features = features[mask]\n",
    "            # features, label = augment_data(features, label, rot=0, h_flip=False, v_flip=False)\n",
    "            features, labels = to_tensors(features, label, labels_map, device=device)\n",
    "            \n",
    "            # split the data into train, test, and validation sets\n",
    "            train_loader, test_loader, val_loader = split_batch(features, labels, batch_size=32)\n",
    "            train_datasets.append(train_loader)\n",
    "            test_datasets.append(test_loader)\n",
    "            val_datasets.append(val_loader)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error on {cat}: {e}\")\n",
    "        \n",
    "    return train_datasets, test_datasets, val_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████| 100/100 [02:59<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "x, y, z = pipeline(image_dir, categories, device, labels_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.TensorDataset at 0x1a81e8eae70>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e5dbcb0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e833620>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8334d0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e78e420>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7b00>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf75c0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf6750>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8645c0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf73e0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e669a30>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3cd40>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3d2e0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e865130>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3d280>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3d550>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e864590>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a850b2c0b0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81ca1a480>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf5e50>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e4aaea0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81cc40d40>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf63c0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7620>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7440>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e866390>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3c230>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7740>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3c980>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a87af85580>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3d460>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81cb962a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e1e0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81cb96240>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3dc70>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e5a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e866780>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e930>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e555520>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3ef00>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e264da0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7530>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8665a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7230>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8662a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3fc50>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3fd70>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7f50>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e7404d0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d409e0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e864320>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3f740>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d41160>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e4a88f0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d41580>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d416d0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf6de0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81cbc7a70>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e864410>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf67b0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf7050>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81cdcf4a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81caa69c0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e70e720>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf6390>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81cf3c860>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e864e00>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e865940>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836cf67e0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e478230>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3c260>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3f950>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e865190>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d41310>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8304a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d42630>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3cf50>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d42750>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e832d20>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3d310>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8331d0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e833260>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8333b0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d432f0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e78dca0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e833b90>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3f0e0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e833ce0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d438f0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d43ad0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81e8644a0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d43980>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3c800>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3c500>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e120>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e6c0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a81caceea0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e360>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3d640>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1a836d3e060>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (train, test, val) in enumerate(zip(x, y, z)):\n",
    "    model = QuickDrawCNN_V2(num_classes=len(labels_map))\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    train(model, optimizer, criterion, train, val, device, epochs=10, save_path=f\"models/model_{i}.pt\")\n",
    "    print(f\"Model {i} trained successfully.\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = 15\n",
    "\n",
    "train_file_paths = [f\"{datasets_dir}/train/train_datasets_{i}.pkl\" for i in range(num_files)]\n",
    "test_file_paths = [f\"{datasets_dir}/test/test_datasets_{i}.pkl\" for i in range(num_files)]\n",
    "val_file_paths = [f\"{datasets_dir}/val/val_datasets_{i}.pkl\" for i in range(num_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categorical split:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing categories 0 to 23...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  96%|█████████▌| 22/23 [01:00<00:02,  2.73s/it]\n",
      "Processing categorical split:   0%|          | 0/15 [01:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m val_buffers \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_files)]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     train_datasets, test_datasets, val_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_files\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessing category \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategories[i:i\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(categories)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mnum_files]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(image_dir, categories, device, labels_map)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m tqdm(categories, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing categories\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# load, process, augment, and split the data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m         features, label \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_standardize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m         features, label \u001b[38;5;241m=\u001b[39m process_data(features, label)\n\u001b[0;32m     15\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;28mlen\u001b[39m(features)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.03\u001b[39m \u001b[38;5;66;03m# keep 30% of the data\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Data Science Projects\\quick_draw\\utils\\processing.py:30\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(dir, category, file_standardize, verbose)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_standardize:\n\u001b[0;32m     28\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m+\u001b[39m category, \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m+\u001b[39m category\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m---> 30\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m label \u001b[38;5;241m=\u001b[39m category\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Round robin system to distribute the categories into the files\n",
    "for i in tqdm(range(0, len(categories), len(categories) // num_files), desc=\"Processing categorical split\"):\n",
    "    print(f\"Processing categories {i} to {min(i + len(categories) // num_files, len(categories))}...\")\n",
    "    \n",
    "    train_buffers = [[] for _ in range(num_files)]\n",
    "    test_buffers = [[] for _ in range(num_files)]\n",
    "    val_buffers = [[] for _ in range(num_files)]\n",
    "        \n",
    "    try:\n",
    "        train_datasets, test_datasets, val_datasets = pipeline(image_dir, categories[i:i + len(categories) // num_files], device, labels_map)\n",
    "        print(f'processing category {categories[i:i + len(categories) // num_files]}')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Distribute datasets into buffers\n",
    "        for idx, (train_data, test_data, val_data) in enumerate(tqdm(zip(train_datasets, test_datasets, val_datasets), desc=\"Distributing datasets\", total=len(train_datasets))):\n",
    "            file_idx = idx % num_files\n",
    "            train_buffers[file_idx].append(train_data)\n",
    "            test_buffers[file_idx].append(test_data)\n",
    "            val_buffers[file_idx].append(val_data)\n",
    "\n",
    "        # Save the buffers\n",
    "        for file_idx in tqdm(range(num_files), desc=\"Saving buffers\"):\n",
    "            with open(train_file_paths[file_idx], \"wb\") as f:\n",
    "                pickle.dump(train_buffers[file_idx], f)\n",
    "            with open(test_file_paths[file_idx], \"wb\") as f:\n",
    "                pickle.dump(test_buffers[file_idx], f)\n",
    "            with open(val_file_paths[file_idx], \"wb\") as f:\n",
    "                pickle.dump(val_buffers[file_idx], f)\n",
    "\n",
    "        # Clear buffers to free up cuda memory\n",
    "        del train_datasets, test_datasets, val_datasets\n",
    "        del train_data, test_data, val_data\n",
    "        del train_buffers, test_buffers, val_buffers\n",
    "        \n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error on {i}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuickDrawCNN_V2().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trumpet.npy': 511}\n"
     ]
    }
   ],
   "source": [
    "with open(val_file_paths[14], \"rb\") as f:\n",
    "    train_datasets = pickle.load(f)\n",
    "\n",
    "category_counts = {label: 0 for label in labels_map}\n",
    "for dataset in train_datasets:\n",
    "    for _, label in dataset:\n",
    "        category_counts[reversed_labels_map[label.item()]] += 1\n",
    "        \n",
    "non_zero_counts = {k: v for k, v in category_counts.items() if v != 0}\n",
    "print(non_zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Iterate trough filed training the model on each before deleting variables and moving to the next\n",
    "for i in range(num_files):\n",
    "\n",
    "    # load train and validation datasets\n",
    "    with open(train_file_paths[i], \"rb\") as f:\n",
    "        train_datasets = pickle.load(f)\n",
    "    with open(val_file_paths[i], \"rb\") as f:\n",
    "        val_datasets = pickle.load(f)\n",
    "        \n",
    "    # convert datasets to dataloaders\n",
    "    train_loader = DataLoader(ConcatDataset(train_datasets), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(ConcatDataset(val_datasets), batch_size=32, shuffle=True)\n",
    "        \n",
    "    # train the model\n",
    "    try:\n",
    "        train_loss, val_loss, train_acc, val_acc = train(model=model,\n",
    "                                                        train_loader=train_loader,\n",
    "                                                        val_loader=val_loader,\n",
    "                                                        epochs=10,\n",
    "                                                        criterion=criterion,\n",
    "                                                        optimizer=optimizer,\n",
    "                                                        device=device)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted manually. Saving current model state...\")\n",
    "        torch.save(model.state_dict(), \"model_state.pth\")\n",
    "        print(\"Model state saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: saves/vars.0.pth\n",
      "Saved to saves/model.0.pth.\n"
     ]
    }
   ],
   "source": [
    "parent_path = 'saves'\n",
    "model_path = f'{parent_path}/model'\n",
    "var_path = f'{parent_path}/vars'\n",
    "\n",
    "varaibles_saved = incremental_save(var_path)\n",
    "with open(varaibles_saved, \"wb\") as f:\n",
    "    pickle.dump(labels_map, f)\n",
    "    pickle.dump(train_loss, f)\n",
    "    pickle.dump(val_loss, f)\n",
    "    pickle.dump(train_acc, f)\n",
    "    pickle.dump(val_acc, f)\n",
    "\n",
    "model_saved = incremental_save(model_path, data=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
